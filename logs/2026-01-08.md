---
created_at: '2026-01-08T13:46:03.166960'
date: '2026-01-08'
tags:
- context/user/GEMINI.md
- context/project/GEMINI.md
- user
- context/project/pyproject.toml
- context
- diff
- context/project/DESIGN.md
- project
- auto-capture
- context/project/README.md
- context/project/git_diff
updated_at: '2026-01-08T15:11:37.711768'
---

## context/project/GEMINI.md (13:46:03)
# GitMem Project Context

## Vision
GitMem 是一个利用 Git 作为后端存储的语义化记忆服务。它通过 MCP (Model Context Protocol) 协议为 AI Agent 提供持久化、可回溯、具备“摄入-消化”闭环能力的长期记忆体。

## Core Principles
1. **摄入重于分类**: 原始记忆以“流水账”形式按日归档（`logs/YYYY-MM-DD.md`），保证上下文完整性。
2. **GitOps 驱动**: 利用 Git Commit 作为事件总线，实现无状态的后台处理。
3. **混合架构 (Hybrid)**: 本地 MCP Server (FastMCP) 负责极速读写，远程 Backend (FastAPI) 负责异步 LLM 归纳。
4. **双层存储**: `logs/` 存放原始数据，`knowledge/` 存放结构化知识。

## Current Status
- [x] **混合架构落地**: 
    - `src/server.py`: 本地客户端，支持 Git 缓存读写 + HTTP Trigger。
    - `src/backend.py`: 远程服务端，FastAPI + Async Queue，支持多租户归纳。
- [x] **存储引擎重构**: 
    - 原始记忆存入 `logs/` 子目录。
    - 每日日志头部自动维护累积 Tags。
- [x] **智能归纳服务 (Digest Worker)**:
    - 实现了基于 Git Diff 的增量解析。
    - 实现了 LLM 驱动的话题路由 (`index.yaml`) 和全量重写归纳。
- [x] **多租户支持**: 通过 Trigger 动态拉取用户 Repo，服务无状态化。

## Key Decisions
- **通信协议**: 本地与后台之间采用 RESTful (`POST /trigger-digest`) 而非 SSE，简化架构。
- **状态追踪**: 严格使用 Git Commit Message 中的 `Ref-Commit` 标记，拒绝本地状态文件。
- **归纳策略**: 采用“全量重写 (Full Rewrite)”模式更新知识库文件，确保文档结构的一致性。

## TODOs
- [ ] **语义化检索重构**:
    - **Smart Recall**: 优先检索 `knowledge/` 中的结构化数据，辅以 `logs/` 的最新增量。
    - **History**: 基于 `knowledge` 文件的版本历史生成话题演进图。
    - **Graph**: 生成基于 `index.yaml` 和引用关系的知识热力图。
- [ ] **高级归纳能力**:
    - 支持冲突检测与人工介入标记。
    - 定期全量 Compaction（合并碎片化的小话题）。

## context/project/README.md (13:46:05)
# GitMem

GitMem is a semantic memory service for AI Agents, backed by Git. It treats memory as a "Living Codebase".

## Architecture

GitMem employs a **Hybrid Architecture** to balance latency and intelligence:

1.  **Local MCP Server (`src/server.py`)**: 
    - Runs locally (Stdio) with your Agent (Claude, Windsurf, Gemini).
    - Provides instant `remember` and `recall` capabilities using a local Git cache.
    - Triggers the backend service upon new writes.

2.  **Backend Service (`src/backend.py`)**:
    - Runs permanently (e.g., on Render).
    - Receives `trigger-digest` signals.
    - Runs an asynchronous **Digest Worker** that uses LLMs to summarize raw logs into structured knowledge.

3.  **Storage (`Git Repo`)**:
    - `logs/`: Raw, append-only daily logs (High Fidelity).
    - `knowledge/`: AI-curated, structured markdown files (High Utility).

## Setup

### 1. Requirements
- Python 3.10+
- OpenAI API Key (for digestion)
- A Git Repository (GitHub/GitLab)

### 2. Installation
```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### 3. Running the Backend
Create `src/digest/.env` with your LLM keys (see `.env.example`).
```bash
python src/backend.py
```

### 4. Configuring Your Agent
Add the local server to your `claude_desktop_config.json` or equivalent:
```json
"gitmem": {
  "command": "python",
  "args": ["/path/to/gitmem/src/server.py"],
  "env": {
    "GITMEM_URL": "https://github.com/your/memory-repo.git",
    "GITMEM_TOKEN": "your-git-token",
    "GITMEM_BACKEND_URL": "http://localhost:8000"
  }
}
```

## Usage
Simply tell your Agent:
> "Remember that the deployment port for QuantServer is 9090."

GitMem will:
1.  Save it to `logs/YYYY-MM-DD.md`.
2.  Trigger the backend.
3.  Update `knowledge/quant_server.md` automatically.

## context/project/DESIGN.md (13:46:08)
# GitMem Technical Design

## 1. 存储架构 (Storage Schema)

### 1.1 目录结构
我们采用 **"双层存储架构"**，区分原始摄入与加工知识。
```text
storage/
├── logs/                 # [User Input] 原始记忆 (Raw Data)
│   ├── YYYY-MM-DD.md     # 按日归档的流水账
│   └── ...
├── knowledge/            # [System Output] 归纳后的知识库 (Digested Data)
│   ├── [topic].md        # 特定话题的结构化知识
│   └── ...
```

### 1.2 Markdown 格式规范 (Raw Logs)
每日日志文件 (`logs/YYYY-MM-DD.md`) 采用追加模式，通过二级标题区分条目。
```markdown
---
date: 2026-01-07
tags: [cumulative, tags, list]
---

## topic_name (10:00:00)
... 记忆正文 ...

## another_topic (11:30:00)
... 更多内容 ...
```

## 2. 核心组件 (Core Components)

### 2.1 MemoryStore (`src/store.py`)
- **Git Wrapper**: 负责 `git init`, `add`, `commit`, `log` 等操作。
- **Metadata Manager**: 负责 Front Matter 的解析与合并。
- **Daily Logger**: 负责将所有 `remember` 请求追加到当日的日志文件中，并更新文件头的累积标签。

### 2.2 Digest Worker (`src/digest/`) - *Planned*
一个独立的后台服务，负责将 `logs/` 中的原始数据归纳为 `knowledge/` 中的结构化知识。
- **架构**: "GitOps for Memory"。
- **状态管理**: 无状态设计。通过 Git Commit Message 中的 `Ref-Commit: <hash>` 标记来追踪处理进度。
- **流程**: 
    1. `git log` 查找上次机器处理的 Commit Hash。
    2. `git diff` 找出自上次处理以来 `logs/` 目录的新增内容。
    3. 调用 LLM 进行语义归纳与合并。
    4. 提交更新到 `knowledge/`，并在 Commit Message 中标记当前的 HEAD Hash。
- **详见**: `src/digest/README.md`

### 2.3 MCP Server (`src/server.py`)
利用 FastMCP 暴露以下工具：
- `remember(content, topic, tags)`: 将记忆追加到 `logs/YYYY-MM-DD.md`。
- `recall(query, topic)`: (短期) 扫描所有日志文件；(长期) 优先查询 `knowledge/`，辅以 `logs/` 的最新增量。
- `history/graph`: *待重构，将基于 knowledge 目录实现。*

## 3. 演进逻辑
- **摄入策略**: 极简追加。用户无需关心文件名，所有上下文自动落盘到当日日志。
- **消化策略**: 异步增量。后台 Worker 负责“整理房间”，将散乱的日志整理为有序的知识。

## context/project/pyproject.toml (13:46:12)
[project]
name = "gitmem"
version = "0.1.0"
description = "Git-backed, Metadata-enriched Memory Service for MCP"
requires-python = ">=3.10"
dependencies = [
    "mcp[cli]>=0.1.0",
    "gitpython>=3.1.0",
    "python-frontmatter>=1.0.0",
    "pyyaml>=6.0",
    "fastapi>=0.100.0",
    "uvicorn>=0.20.0",
    "httpx>=0.24.0",
    "openai>=1.0.0",
    "python-dotenv>=1.0.0",
    "pydantic>=2.0.0"
]

[project.scripts]
gitmem = "src.server:main"

## context/user/GEMINI.md (13:46:14)
## Gemini Added Memories
- For QuantServer project, always follow these core principles: 1) NO hidden defaults for quant variables (must be explicit/from config); 2) Transparent error reporting (no masking errors with fake 100% lines); 3) Strict data integrity validation before calculation; 4) Absolute logic parity between backtest and production modules.
- MANDATORY: All UI/Frontend changes in QuantServer must be verified locally before pushing to Render. Workflow: 1) Run local server via run_server.py; 2) Use browser tools to visit http://localhost:8000/view/QQQ/1y; 3) Check console for Syntax/Type errors; 4) Verify chart rendering and interactions. Do NOT push if local verification fails.

## context/project/git_diff (13:46:17)
diff --git a/pyproject.toml b/pyproject.toml
index ec7d7d4..ff97675 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -7,7 +7,13 @@ dependencies = [
     "mcp[cli]>=0.1.0",
     "gitpython>=3.1.0",
     "python-frontmatter>=1.0.0",
-    "pyyaml>=6.0"
+    "pyyaml>=6.0",
+    "fastapi>=0.100.0",
+    "uvicorn>=0.20.0",
+    "httpx>=0.24.0",
+    "openai>=1.0.0",
+    "python-dotenv>=1.0.0",
+    "pydantic>=2.0.0"
 ]
 
 [project.scripts]
diff --git a/src/__pycache__/store.cpython-313.pyc b/src/__pycache__/store.cpython-313.pyc
index 74f48a7..20b5d81 100644
Binary files a/src/__pycache__/store.cpython-313.pyc and b/src/__pycache__/store.cpython-313.pyc differ
diff --git a/src/server.py b/src/server.py
index f5b4e6c..d627972 100644
--- a/src/server.py
+++ b/src/server.py
@@ -1,5 +1,6 @@
 import sys
 import os
+import subprocess
 
 # Add the project root to sys.path to ensure 'src' is findable
 project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
@@ -25,6 +26,94 @@ except Exception as e:
 
 import httpx
 
+# Configuration for Context Sources
+CONTEXT_SOURCES = {
+    "project": [
+        "GEMINI.md", "README.md", "DESIGN.md", "ARCHITECTURE.md",
+        "pyproject.toml", "package.json", "requirements.txt"
+    ],
+    "user": [
+        "~/.gemini/GEMINI.md",
+        "~/.gemini/memory.md"
+    ],
+    "system": [
+        ".cursorrules",
+        ".editorconfig"
+    ]
+}
+
+@mcp.tool()
+def capture_context(scope: str = "all", git_url: str = None, git_token: str = None) -> str:
+    """
+    Auto-capture project context and working state into memory.
+    
+    Args:
+        scope: 'project', 'user', 'system', or 'all'. Determines which files to scan.
+        git_url: Remote Git URL for storage.
+        git_token: Remote Git Token.
+    """
+    logs = []
+    scopes_to_process = []
+    
+    if scope == "all":
+        scopes_to_process = ["project", "user", "system"]
+    elif scope in CONTEXT_SOURCES:
+        scopes_to_process = [scope]
+    else:
+        return f"Error: Invalid scope '{scope}'. Valid scopes: {list(CONTEXT_SOURCES.keys())} or 'all'."
+
+    # 1. Capture Files
+    for s in scopes_to_process:
+        patterns = CONTEXT_SOURCES.get(s, [])
+        for pattern in patterns:
+            # Handle user expansion and relative paths
+            full_path = os.path.expanduser(pattern)
+            if not os.path.isabs(full_path):
+                full_path = os.path.abspath(full_path)
+            
+            if os.path.exists(full_path) and os.path.isfile(full_path):
+                try:
+                    with open(full_path, 'r', encoding='utf-8') as f:
+                        content = f.read()
+                    
+                    # Store it
+                    # Topic convention: context/{scope}/{filename}
+                    filename = os.path.basename(full_path)
+                    topic = f"context/{s}/{filename}"
+                    
+                    res = store.remember(
+                        content=content,
+                        topic=topic,
+                        tags=["context", s, "auto-capture"],
+                        git_url=git_url,
+                        git_token=git_token
+                    )
+                    logs.append(f"[File] {filename}: {res}")
+                except Exception as e:
+                    logs.append(f"[Error] Failed to read {full_path}: {e}")
+
+    # 2. Capture Git Diff (Only for project scope or all)
+    if "project" in scopes_to_process:
+        try:
+            # Check for unstaged changes
+            diff_proc = subprocess.run(["git", "diff", "HEAD"], capture_output=True, text=True)
+            if diff_proc.returncode == 0 and diff_proc.stdout.strip():
+                diff_content = diff_proc.stdout
+                res = store.remember(
+                    content=diff_content,
+                    topic="context/project/git_diff",
+                    tags=["context", "project", "diff"],
+                    git_url=git_url,
+                    git_token=git_token
+                )
+                logs.append(f"[Diff] Git Diff captured: {res}")
+            else:
+                logs.append("[Diff] No active changes found in git.")
+        except Exception as e:
+            logs.append(f"[Diff] Error capturing git diff: {e}")
+
+    return "\n".join(logs)
+
 @mcp.tool()
 def remember(content: str, topic: str = "global", tags: List[str] = None, 
              dependencies: List[str] = None, git_url: str = None, git_token: str = None) -> str:
@@ -116,5 +205,8 @@ def sync() -> str:
     """
     return store.sync()
 
-if __name__ == "__main__":
+def main():
     mcp.run()
+
+if __name__ == "__main__":
+    main()
diff --git a/src/store.py b/src/store.py
index b70a159..cc70ecc 100644
--- a/src/store.py
+++ b/src/store.py
@@ -208,4 +208,18 @@ class MemoryStore:
                 # Just listing files for now as "nodes"
                 graph[filename.replace(".md", "")] = ["daily_log"]
             return graph
-        except: return {}
\ No newline at end of file
+        except: return {}
+
+    def sync(self, git_url: Optional[str] = None, git_token: Optional[str] = None) -> str:
+        """Manually pull and push to the remote repository."""
+        git_url = git_url or os.environ.get("GITMEM_URL")
+        git_token = git_token or os.environ.get("GITMEM_TOKEN")
+        if not git_url:
+            return "Error: GITMEM_URL is not set."
+        try:
+            repo = self._prepare_repo(git_url, git_token)
+            repo.remotes.origin.pull()
+            repo.remotes.origin.push()
+            return f"Successfully synced with {git_url}"
+        except Exception as e:
+            return f"Sync failed: {str(e)}"
\ No newline at end of file

## context/project/GEMINI.md (15:11:26)
# GitMem Project Context

## Vision
GitMem 是一个利用 Git 作为后端存储的语义化记忆服务。它通过 MCP (Model Context Protocol) 协议为 AI Agent 提供持久化、可回溯、具备“摄入-消化”闭环能力的长期记忆体。

## Core Principles
1. **摄入重于分类**: 原始记忆以“流水账”形式按日归档（`logs/YYYY-MM-DD.md`），保证上下文完整性。
2. **GitOps 驱动**: 利用 Git Commit 作为事件总线，实现无状态的后台处理。
3. **混合架构 (Hybrid)**: 本地 MCP Server (FastMCP) 负责极速读写，远程 Backend (FastAPI) 负责异步 LLM 归纳。
4. **双层存储**: `logs/` 存放原始数据，`knowledge/` 存放结构化知识。

## Current Status
- [x] **混合架构落地**: 
    - `src/server.py`: 本地客户端，支持 Git 缓存读写 + HTTP Trigger。
    - `src/backend.py`: 远程服务端，FastAPI + Async Queue，支持多租户归纳。
- [x] **存储引擎重构**: 
    - 原始记忆存入 `logs/` 子目录。
    - 每日日志头部自动维护累积 Tags。
- [x] **智能归纳服务 (Digest Worker)**:
    - 实现了基于 Git Diff 的增量解析。
    - 实现了 LLM 驱动的话题路由 (`index.yaml`) 和全量重写归纳。
- [x] **多租户支持**: 通过 Trigger 动态拉取用户 Repo，服务无状态化。

## Key Decisions
- **通信协议**: 本地与后台之间采用 RESTful (`POST /trigger-digest`) 而非 SSE，简化架构。
- **状态追踪**: 严格使用 Git Commit Message 中的 `Ref-Commit` 标记，拒绝本地状态文件。
- **归纳策略**: 采用“全量重写 (Full Rewrite)”模式更新知识库文件，确保文档结构的一致性。

## TODOs
- [ ] **语义化检索重构**:
    - **Smart Recall**: 优先检索 `knowledge/` 中的结构化数据，辅以 `logs/` 的最新增量。
    - **History**: 基于 `knowledge` 文件的版本历史生成话题演进图。
    - **Graph**: 生成基于 `index.yaml` 和引用关系的知识热力图。
- [ ] **高级归纳能力**:
    - 支持冲突检测与人工介入标记。
    - 定期全量 Compaction（合并碎片化的小话题）。

## context/project/README.md (15:11:29)
# GitMem

GitMem is a semantic memory service for AI Agents, backed by Git. It treats memory as a "Living Codebase".

## Architecture

GitMem employs a **Hybrid Architecture** to balance latency and intelligence:

1.  **Local MCP Server (`src/server.py`)**: 
    - Runs locally (Stdio) with your Agent (Claude, Windsurf, Gemini).
    - Provides instant `remember` and `recall` capabilities using a local Git cache.
    - Triggers the backend service upon new writes.

2.  **Backend Service (`src/backend.py`)**:
    - Runs permanently (e.g., on Render).
    - Receives `trigger-digest` signals.
    - Runs an asynchronous **Digest Worker** that uses LLMs to summarize raw logs into structured knowledge.

3.  **Storage (`Git Repo`)**:
    - `logs/`: Raw, append-only daily logs (High Fidelity).
    - `knowledge/`: AI-curated, structured markdown files (High Utility).

## Setup

### 1. Requirements
- Python 3.10+
- OpenAI API Key (for digestion)
- A Git Repository (GitHub/GitLab)

### 2. Installation
```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### 3. Running the Backend
Create `src/digest/.env` with your LLM keys (see `.env.example`).
```bash
python src/backend.py
```

### 4. Configuring Your Agent
Add the local server to your `claude_desktop_config.json` or equivalent:
```json
"gitmem": {
  "command": "python",
  "args": ["/path/to/gitmem/src/server.py"],
  "env": {
    "GITMEM_URL": "https://github.com/your/memory-repo.git",
    "GITMEM_TOKEN": "your-git-token",
    "GITMEM_BACKEND_URL": "http://localhost:8000"
  }
}
```

## Usage
Simply tell your Agent:
> "Remember that the deployment port for QuantServer is 9090."

GitMem will:
1.  Save it to `logs/YYYY-MM-DD.md`.
2.  Trigger the backend.
3.  Update `knowledge/quant_server.md` automatically.

## context/project/DESIGN.md (15:11:32)
# GitMem Technical Design

## 1. 存储架构 (Storage Schema)

### 1.1 目录结构
我们采用 **"双层存储架构"**，区分原始摄入与加工知识。
```text
storage/
├── logs/                 # [User Input] 原始记忆 (Raw Data)
│   ├── YYYY-MM-DD.md     # 按日归档的流水账
│   └── ...
├── knowledge/            # [System Output] 归纳后的知识库 (Digested Data)
│   ├── [topic].md        # 特定话题的结构化知识
│   └── ...
```

### 1.2 Markdown 格式规范 (Raw Logs)
每日日志文件 (`logs/YYYY-MM-DD.md`) 采用追加模式，通过二级标题区分条目。
```markdown
---
date: 2026-01-07
tags: [cumulative, tags, list]
---

## topic_name (10:00:00)
... 记忆正文 ...

## another_topic (11:30:00)
... 更多内容 ...
```

## 2. 核心组件 (Core Components)

### 2.1 MemoryStore (`src/store.py`)
- **Git Wrapper**: 负责 `git init`, `add`, `commit`, `log` 等操作。
- **Metadata Manager**: 负责 Front Matter 的解析与合并。
- **Daily Logger**: 负责将所有 `remember` 请求追加到当日的日志文件中，并更新文件头的累积标签。

### 2.2 Digest Worker (`src/digest/`) - *Planned*
一个独立的后台服务，负责将 `logs/` 中的原始数据归纳为 `knowledge/` 中的结构化知识。
- **架构**: "GitOps for Memory"。
- **状态管理**: 无状态设计。通过 Git Commit Message 中的 `Ref-Commit: <hash>` 标记来追踪处理进度。
- **流程**: 
    1. `git log` 查找上次机器处理的 Commit Hash。
    2. `git diff` 找出自上次处理以来 `logs/` 目录的新增内容。
    3. 调用 LLM 进行语义归纳与合并。
    4. 提交更新到 `knowledge/`，并在 Commit Message 中标记当前的 HEAD Hash。
- **详见**: `src/digest/README.md`

### 2.3 MCP Server (`src/server.py`)
利用 FastMCP 暴露以下工具：
- `remember(content, topic, tags)`: 将记忆追加到 `logs/YYYY-MM-DD.md`。
- `recall(query, topic)`: (短期) 扫描所有日志文件；(长期) 优先查询 `knowledge/`，辅以 `logs/` 的最新增量。
- `history/graph`: *待重构，将基于 knowledge 目录实现。*

## 3. 演进逻辑
- **摄入策略**: 极简追加。用户无需关心文件名，所有上下文自动落盘到当日日志。
- **消化策略**: 异步增量。后台 Worker 负责“整理房间”，将散乱的日志整理为有序的知识。

## context/project/pyproject.toml (15:11:35)
[project]
name = "gitmem"
version = "0.1.0"
description = "Git-backed, Metadata-enriched Memory Service for MCP"
requires-python = ">=3.10"
dependencies = [
    "mcp[cli]>=0.1.0",
    "gitpython>=3.1.0",
    "python-frontmatter>=1.0.0",
    "pyyaml>=6.0",
    "fastapi>=0.100.0",
    "uvicorn>=0.20.0",
    "httpx>=0.24.0",
    "openai>=1.0.0",
    "python-dotenv>=1.0.0",
    "pydantic>=2.0.0"
]

[project.scripts]
gitmem = "src.server:main"

## context/user/GEMINI.md (15:11:37)
## Gemini Added Memories
- For QuantServer project, always follow these core principles: 1) NO hidden defaults for quant variables (must be explicit/from config); 2) Transparent error reporting (no masking errors with fake 100% lines); 3) Strict data integrity validation before calculation; 4) Absolute logic parity between backtest and production modules.
- MANDATORY: All UI/Frontend changes in QuantServer must be verified locally before pushing to Render. Workflow: 1) Run local server via run_server.py; 2) Use browser tools to visit http://localhost:8000/view/QQQ/1y; 3) Check console for Syntax/Type errors; 4) Verify chart rendering and interactions. Do NOT push if local verification fails.