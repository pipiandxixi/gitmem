---
created_at: '2026-01-09T23:22:35.089747'
date: '2026-01-09'
tags:
- context/project/README.md
- workflow
- context/project/git_diff
- rule
- context/project/pyproject.toml
- project
- project:gitmem
- diff
- user
- testing/rules
- context/project/DESIGN.md
- testing
- context/project/GEMINI.md
- context/user/GEMINI.md
- auto-capture
- context
updated_at: '2026-01-09T23:32:58.645905'
---

## testing/rules (23:22:35)
[Context: gitmem] 每次测试之前要清空我们的远程repo

## context/project/GEMINI.md (23:32:38)
[Context: gitmem] Source: GEMINI.md
# GitMem Project Context

## Vision
GitMem 是一个利用 Git 作为后端存储的语义化记忆服务。它通过 MCP (Model Context Protocol) 协议为 AI Agent 提供持久化、可回溯、具备“摄入-消化”闭环能力的长期记忆体。

## Core Principles
1. **摄入重于分类**: 原始记忆以“流水账”形式按日归档（`logs/YYYY-MM-DD.md`），保证上下文完整性。
2. **GitOps 驱动**: 利用 Git Commit 作为事件总线，实现无状态的后台处理。
3. **混合架构 (Hybrid)**: 本地 MCP Server (FastMCP) 负责极速读写，远程 Backend (FastAPI) 负责异步 LLM 归纳。
4. **双层存储**: `logs/` 存放原始数据，`knowledge/` 存放结构化知识。

## Current Status
- [x] **混合架构落地**: 
    - `src/server.py`: 本地客户端，支持 Git 缓存读写 + HTTP Trigger。
    - `src/backend.py`: 远程服务端，FastAPI + Async Queue，支持多租户归纳。
- [x] **存储引擎重构**: 
    - 原始记忆存入 `logs/` 子目录。
    - 每日日志头部自动维护累积 Tags。
- [x] **智能归纳服务 (Digest Worker)**:
    - 实现了基于 Git Diff 的增量解析。
    - 实现了 LLM 驱动的话题路由 (`index.yaml`) 和全量重写归纳。
- [x] **多租户支持**: 通过 Trigger 动态拉取用户 Repo，服务无状态化。

## Key Decisions
- **通信协议**: 本地与后台之间采用 RESTful (`POST /trigger-digest`) 而非 SSE，简化架构。
- **状态追踪**: 严格使用 Git Commit Message 中的 `Ref-Commit` 标记，拒绝本地状态文件。
- **归纳策略**: 采用“全量重写 (Full Rewrite)”模式更新知识库文件，确保文档结构的一致性。

## TODOs
- [ ] **语义化检索重构**:
    - **Smart Recall**: 优先检索 `knowledge/` 中的结构化数据，辅以 `logs/` 的最新增量。
    - **History**: 基于 `knowledge` 文件的版本历史生成话题演进图。
    - **Graph**: 生成基于 `index.yaml` 和引用关系的知识热力图。
- [ ] **高级归纳能力**:
    - 支持冲突检测与人工介入标记。
    - 定期全量 Compaction（合并碎片化的小话题）。

## context/project/README.md (23:32:42)
[Context: gitmem] Source: README.md
# GitMem

GitMem is a semantic memory service for AI Agents, backed by Git. It treats memory as a "Living Codebase".

## Architecture

GitMem employs a **Hybrid Architecture** to balance latency and intelligence:

1.  **Local MCP Server (`src/server.py`)**: 
    - Runs locally (Stdio) with your Agent (Claude, Windsurf, Gemini).
    - Provides instant `remember` and `recall` capabilities using a local Git cache.
    - Triggers the backend service upon new writes.

2.  **Backend Service (`src/backend.py`)**:
    - Runs permanently (e.g., on Render).
    - Receives `trigger-digest` signals.
    - Runs an asynchronous **Digest Worker** that uses LLMs to summarize raw logs into structured knowledge.

3.  **Storage (`Git Repo`)**:
    - `logs/`: Raw, append-only daily logs (High Fidelity).
    - `knowledge/`: AI-curated, structured markdown files (High Utility).

## Setup

### 1. Requirements
- Python 3.10+
- OpenAI API Key (for digestion)
- A Git Repository (GitHub/GitLab)

### 2. Installation
```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### 3. Running the Backend
Create `src/digest/.env` with your LLM keys (see `.env.example`).
```bash
python src/backend.py
```

### 4. Configuring Your Agent
Add the local server to your `claude_desktop_config.json` or equivalent:
```json
"gitmem": {
  "command": "python",
  "args": ["/path/to/gitmem/src/server.py"],
  "env": {
    "GITMEM_URL": "https://github.com/your/memory-repo.git",
    "GITMEM_TOKEN": "your-git-token",
    "GITMEM_BACKEND_URL": "http://localhost:8000"
  }
}
```

## Usage
Simply tell your Agent:
> "Remember that the deployment port for QuantServer is 9090."

GitMem will:
1.  Save it to `logs/YYYY-MM-DD.md`.
2.  Trigger the backend.
3.  Update `knowledge/quant_server.md` automatically.

## context/project/DESIGN.md (23:32:46)
[Context: gitmem] Source: DESIGN.md
# GitMem Technical Design

## 1. 存储架构 (Storage Schema)

### 1.1 目录结构
我们采用 **"双层存储架构"**，区分原始摄入与加工知识。
```text
storage/
├── logs/                 # [User Input] 原始记忆 (Raw Data)
│   ├── YYYY-MM-DD.md     # 按日归档的流水账
│   └── ...
├── knowledge/            # [System Output] 归纳后的知识库 (Digested Data)
│   ├── [topic].md        # 特定话题的结构化知识
│   └── ...
```

### 1.2 Markdown 格式规范 (Raw Logs)
每日日志文件 (`logs/YYYY-MM-DD.md`) 采用追加模式，通过二级标题区分条目。
```markdown
---
date: 2026-01-07
tags: [cumulative, tags, list]
---

## topic_name (10:00:00)
... 记忆正文 ...

## another_topic (11:30:00)
... 更多内容 ...
```

## 2. 核心组件 (Core Components)

### 2.1 MemoryStore (`src/store.py`)
- **Git Wrapper**: 负责 `git init`, `add`, `commit`, `log` 等操作。
- **Metadata Manager**: 负责 Front Matter 的解析与合并。
- **Daily Logger**: 负责将所有 `remember` 请求追加到当日的日志文件中，并更新文件头的累积标签。

### 2.2 Digest Worker (`src/digest/`) - *Planned*
一个独立的后台服务，负责将 `logs/` 中的原始数据归纳为 `knowledge/` 中的结构化知识。
- **架构**: "GitOps for Memory"。
- **状态管理**: 无状态设计。通过 Git Commit Message 中的 `Ref-Commit: <hash>` 标记来追踪处理进度。
- **流程**: 
    1. `git log` 查找上次机器处理的 Commit Hash。
    2. `git diff` 找出自上次处理以来 `logs/` 目录的新增内容。
    3. 调用 LLM 进行语义归纳与合并。
    4. 提交更新到 `knowledge/`，并在 Commit Message 中标记当前的 HEAD Hash。
- **详见**: `src/digest/README.md`

### 2.3 MCP Server (`src/server.py`)
利用 FastMCP 暴露以下工具：
- `remember(content, topic, tags)`: 将记忆追加到 `logs/YYYY-MM-DD.md`。
- `recall(query, topic)`: (短期) 扫描所有日志文件；(长期) 优先查询 `knowledge/`，辅以 `logs/` 的最新增量。
- `history/graph`: *待重构，将基于 knowledge 目录实现。*

## 3. 演进逻辑
- **摄入策略**: 极简追加。用户无需关心文件名，所有上下文自动落盘到当日日志。
- **消化策略**: 异步增量。后台 Worker 负责“整理房间”，将散乱的日志整理为有序的知识。

## context/project/pyproject.toml (23:32:50)
[Context: gitmem] Source: pyproject.toml
[project]
name = "gitmem"
version = "0.1.0"
description = "Git-backed, Metadata-enriched Memory Service for MCP"
requires-python = ">=3.10"
dependencies = [
    "mcp[cli]>=0.1.0",
    "gitpython>=3.1.0",
    "python-frontmatter>=1.0.0",
    "pyyaml>=6.0",
    "fastapi>=0.100.0",
    "uvicorn>=0.20.0",
    "httpx>=0.24.0",
    "openai>=1.0.0",
    "python-dotenv>=1.0.0",
    "pydantic>=2.0.0"
]

[project.scripts]
gitmem = "src.server:main"

## context/user/GEMINI.md (23:32:54)
[Context: gitmem] Source: GEMINI.md
## Gemini Added Memories
- For QuantServer project, always follow these core principles: 1) NO hidden defaults for quant variables (must be explicit/from config); 2) Transparent error reporting (no masking errors with fake 100% lines); 3) Strict data integrity validation before calculation; 4) Absolute logic parity between backtest and production modules.
- MANDATORY: All UI/Frontend changes in QuantServer must be verified locally before pushing to Render. Workflow: 1) Run local server via run_server.py; 2) Use browser tools to visit http://localhost:8000/view/QQQ/1y; 3) Check console for Syntax/Type errors; 4) Verify chart rendering and interactions. Do NOT push if local verification fails.

## context/project/git_diff (23:32:58)
[Project: gitmem] Git Diff Snapshot:
diff --git a/backend.log b/backend.log
index 423bd51..64e376b 100644
--- a/backend.log
+++ b/backend.log
@@ -1,5 +1,220 @@
-INFO:     Started server process [8580]
+INFO:     Started server process [56831]
 INFO:     Waiting for application startup.
-2026-01-07 21:50:19,300 - gitmem-backend - INFO - Digest consumer started.
+2026-01-09 08:17:55,974 - gitmem-backend - INFO - Digest consumer started.
 INFO:     Application startup complete.
 INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
+INFO:     127.0.0.1:53691 - "POST /trigger-digest HTTP/1.1" 200 OK
+2026-01-09 08:18:56,713 - gitmem-backend - INFO - Processing digest for: https://github.com/pipiandxixi/gitmem.git
+2026-01-09 08:18:56,716 - gitmem-backend - INFO - Updating temp repo: /var/folders/z9/b2gg3cfd08j6xb2ft3ks0s700000gn/T/gitmem-backend/ca070312e156
+2026-01-09 08:18:58,183 - digest-worker - INFO - Starting Digest Worker (Cognitive Schema Mode)...
+2026-01-09 08:18:58,229 - digest-worker - INFO - Last Hash: 381e7b5d042c2124f338d65f8e3836978c14dba0, Current Head: 52bc43fc1d1e1cedb78bf4fa37deda8f0e0c3de4
+2026-01-09 08:18:58,243 - digest-worker - INFO - Found 3 pending commits.
+2026-01-09 08:18:58,259 - digest-worker - INFO - Diff file: None
+2026-01-09 08:18:58,259 - digest-worker - INFO - Diff file: None
+2026-01-09 08:18:58,273 - digest-worker - INFO - Diff file: logs/2026-01-08.md
+2026-01-09 08:18:58,273 - digest-worker - INFO - RAW PATCH: @@ -0,0 +1,13 @@
++---
++created_at: '2026-01-08T23:43:48.628867'
++date: '2026-01-08'
++tags:
++- restart_rule
++- backend
++- rule
++- procedure
++updated_at: '2026-01-08T23:43:48.628871'
++---
++
++## restart_rule (23:43:48)
++Rule: Whenever we modify the backend service in the project, we must restart it to apply the changes. This ensures the service is running the latest code.
+\ No newline at end of file
+
+2026-01-09 08:18:58,273 - digest-worker - INFO - Checking line: '---'
+2026-01-09 08:18:58,273 - digest-worker - INFO - Checking line: 'created_at: '2026-01-08T23:43:48.628867''
+2026-01-09 08:18:58,273 - digest-worker - INFO - Checking line: 'date: '2026-01-08''
+2026-01-09 08:18:58,273 - digest-worker - INFO - Checking line: 'tags:'
+2026-01-09 08:18:58,273 - digest-worker - INFO - Checking line: '- restart_rule'
+2026-01-09 08:18:58,273 - digest-worker - INFO - Checking line: '- backend'
+2026-01-09 08:18:58,273 - digest-worker - INFO - Checking line: '- rule'
+2026-01-09 08:18:58,273 - digest-worker - INFO - Checking line: '- procedure'
+2026-01-09 08:18:58,273 - digest-worker - INFO - Checking line: 'updated_at: '2026-01-08T23:43:48.628871''
+2026-01-09 08:18:58,273 - digest-worker - INFO - Checking line: '---'
+2026-01-09 08:18:58,273 - digest-worker - INFO - Checking line: ''
+2026-01-09 08:18:58,273 - digest-worker - INFO - Checking line: '## restart_rule (23:43:48)'
+2026-01-09 08:18:58,273 - digest-worker - INFO - MATCHED: restart_rule
+2026-01-09 08:18:58,273 - digest-worker - INFO - Checking line: 'Rule: Whenever we modify the backend service in the project, we must restart it to apply the changes. This ensures the service is running the latest code.'
+2026-01-09 08:18:58,286 - digest-worker - INFO - Diff file: logs/2026-01-09.md
+2026-01-09 08:18:58,286 - digest-worker - INFO - RAW PATCH: @@ -0,0 +1,13 @@
++---
++created_at: '2026-01-09T08:18:55.022902'
++date: '2026-01-09'
++tags:
++- restart_rule
++- backend
++- rule
++- procedure
++updated_at: '2026-01-09T08:18:55.022906'
++---
++
++## restart_rule (08:18:55)
++Rule: Whenever we modify the backend service in the project, we must restart it to apply the changes. This ensures the service is running the latest code.
+\ No newline at end of file
+
+2026-01-09 08:18:58,286 - digest-worker - INFO - Checking line: '---'
+2026-01-09 08:18:58,287 - digest-worker - INFO - Checking line: 'created_at: '2026-01-09T08:18:55.022902''
+2026-01-09 08:18:58,287 - digest-worker - INFO - Checking line: 'date: '2026-01-09''
+2026-01-09 08:18:58,287 - digest-worker - INFO - Checking line: 'tags:'
+2026-01-09 08:18:58,287 - digest-worker - INFO - Checking line: '- restart_rule'
+2026-01-09 08:18:58,287 - digest-worker - INFO - Checking line: '- backend'
+2026-01-09 08:18:58,287 - digest-worker - INFO - Checking line: '- rule'
+2026-01-09 08:18:58,287 - digest-worker - INFO - Checking line: '- procedure'
+2026-01-09 08:18:58,287 - digest-worker - INFO - Checking line: 'updated_at: '2026-01-09T08:18:55.022906''
+2026-01-09 08:18:58,287 - digest-worker - INFO - Checking line: '---'
+2026-01-09 08:18:58,287 - digest-worker - INFO - Checking line: ''
+2026-01-09 08:18:58,287 - digest-worker - INFO - Checking line: '## restart_rule (08:18:55)'
+2026-01-09 08:18:58,287 - digest-worker - INFO - MATCHED: restart_rule
+2026-01-09 08:18:58,287 - digest-worker - INFO - Checking line: 'Rule: Whenever we modify the backend service in the project, we must restart it to apply the changes. This ensures the service is running the latest code.'
+2026-01-09 08:18:58,287 - digest-worker - INFO - Extracted 2 new entries.
+2026-01-09 08:19:13,758 - httpx - INFO - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
+2026-01-09 08:19:13,764 - digest-worker - INFO - Routed 'restart_rule' -> 'preferences'
+2026-01-09 08:19:59,080 - httpx - INFO - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
+2026-01-09 08:19:59,083 - digest-worker - INFO - Routed 'restart_rule' -> 'misc'
+2026-01-09 08:19:59,084 - digest-worker - INFO - Merging updates into preferences.md...
+2026-01-09 08:20:28,036 - httpx - INFO - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
+2026-01-09 08:20:28,040 - digest-worker - INFO - Merging updates into misc.md...
+2026-01-09 08:21:12,730 - httpx - INFO - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
+2026-01-09 08:21:12,831 - digest-worker - INFO - Committed digest work. Ref: 52bc43fc1d1e1cedb78bf4fa37deda8f0e0c3de4
+2026-01-09 08:21:14,534 - digest-worker - INFO - Pushed changes to remote.
+2026-01-09 08:21:14,536 - gitmem-backend - INFO - Finished digest for: https://github.com/pipiandxixi/gitmem.git
+INFO:     127.0.0.1:55093 - "POST /trigger-digest HTTP/1.1" 200 OK
+2026-01-09 15:37:10,039 - gitmem-backend - INFO - Processing digest for: https://github.com/pipiandxixi/gitmem.git
+2026-01-09 15:37:10,040 - gitmem-backend - INFO - Updating temp repo: /var/folders/z9/b2gg3cfd08j6xb2ft3ks0s700000gn/T/gitmem-backend/ca070312e156
+2026-01-09 15:37:11,449 - digest-worker - INFO - Starting Digest Worker (Cognitive Schema Mode)...
+2026-01-09 15:37:11,481 - digest-worker - INFO - Last Hash: 52bc43fc1d1e1cedb78bf4fa37deda8f0e0c3de4, Current Head: ed38ca68aeee7008e88d156b9c7ddc134ccece6d
+2026-01-09 15:37:11,492 - digest-worker - INFO - Found 2 pending commits.
+2026-01-09 15:37:11,505 - digest-worker - INFO - Diff file: None
+2026-01-09 15:37:11,505 - digest-worker - INFO - Diff file: None
+2026-01-09 15:37:11,505 - digest-worker - INFO - Diff file: None
+2026-01-09 15:37:11,505 - digest-worker - INFO - Diff file: None
+2026-01-09 15:37:11,515 - digest-worker - INFO - Diff file: logs/2026-01-09.md
+2026-01-09 15:37:11,515 - digest-worker - INFO - RAW PATCH: @@ -0,0 +1,14 @@
++---
++created_at: '2026-01-09T15:37:08.407212'
++date: '2026-01-09'
++tags:
++- mcp-server
++- development
++- mcp_reload_reminder
++- project:gitmem
++- reminder
++updated_at: '2026-01-09T15:37:08.407216'
++---
++
++## mcp_reload_reminder (15:37:08)
++[Project: gitmem] Reminder: Whenever the MCP server code is modified, remind the user to reload the MCP server environment to apply changes.
+\ No newline at end of file
+
+2026-01-09 15:37:11,515 - digest-worker - INFO - Checking line: '---'
+2026-01-09 15:37:11,515 - digest-worker - INFO - Checking line: 'created_at: '2026-01-09T15:37:08.407212''
+2026-01-09 15:37:11,515 - digest-worker - INFO - Checking line: 'date: '2026-01-09''
+2026-01-09 15:37:11,515 - digest-worker - INFO - Checking line: 'tags:'
+2026-01-09 15:37:11,515 - digest-worker - INFO - Checking line: '- mcp-server'
+2026-01-09 15:37:11,515 - digest-worker - INFO - Checking line: '- development'
+2026-01-09 15:37:11,515 - digest-worker - INFO - Checking line: '- mcp_reload_reminder'
+2026-01-09 15:37:11,515 - digest-worker - INFO - Checking line: '- project:gitmem'
+2026-01-09 15:37:11,515 - digest-worker - INFO - Checking line: '- reminder'
+2026-01-09 15:37:11,515 - digest-worker - INFO - Checking line: 'updated_at: '2026-01-09T15:37:08.407216''
+2026-01-09 15:37:11,515 - digest-worker - INFO - Checking line: '---'
+2026-01-09 15:37:11,515 - digest-worker - INFO - Checking line: ''
+2026-01-09 15:37:11,515 - digest-worker - INFO - Checking line: '## mcp_reload_reminder (15:37:08)'
+2026-01-09 15:37:11,515 - digest-worker - INFO - MATCHED: mcp_reload_reminder
+2026-01-09 15:37:11,515 - digest-worker - INFO - Checking line: '[Project: gitmem] Reminder: Whenever the MCP server code is modified, remind the user to reload the MCP server environment to apply changes.'
+2026-01-09 15:37:11,516 - digest-worker - INFO - Extracted 1 new entries.
+2026-01-09 15:37:19,159 - httpx - INFO - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
+2026-01-09 15:37:19,170 - digest-worker - INFO - Routed 'mcp_reload_reminder' -> 'todos'
+2026-01-09 15:37:19,170 - digest-worker - INFO - Merging updates into todos.md...
+2026-01-09 15:37:35,545 - httpx - INFO - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
+2026-01-09 15:37:35,632 - digest-worker - INFO - Committed digest work. Ref: ed38ca68aeee7008e88d156b9c7ddc134ccece6d
+2026-01-09 15:37:37,201 - digest-worker - INFO - Pushed changes to remote.
+2026-01-09 15:37:37,201 - gitmem-backend - INFO - Finished digest for: https://github.com/pipiandxixi/gitmem.git
+INFO:     127.0.0.1:55318 - "POST /trigger-digest HTTP/1.1" 200 OK
+2026-01-09 23:22:37,447 - gitmem-backend - INFO - Processing digest for: https://github.com/pipiandxixi/gitmem.git
+2026-01-09 23:22:37,449 - gitmem-backend - INFO - Updating temp repo: /var/folders/z9/b2gg3cfd08j6xb2ft3ks0s700000gn/T/gitmem-backend/ca070312e156
+2026-01-09 23:22:39,756 - digest-worker - INFO - Starting Digest Worker (Cognitive Schema Mode)...
+2026-01-09 23:22:39,788 - digest-worker - INFO - Last Hash: ed38ca68aeee7008e88d156b9c7ddc134ccece6d, Current Head: 305ea3ab130fce0713697fb20a0bdcf507191ad0
+2026-01-09 23:22:39,800 - digest-worker - INFO - Found 4 pending commits.
+2026-01-09 23:22:39,811 - digest-worker - INFO - Diff file: None
+2026-01-09 23:22:39,811 - digest-worker - INFO - Diff file: None
+2026-01-09 23:22:39,822 - digest-worker - INFO - Diff file: logs/2026-01-09.md
+2026-01-09 23:22:39,822 - digest-worker - INFO - RAW PATCH: @@ -0,0 +1,13 @@
++---
++created_at: '2026-01-09T15:15:37Z'
++date: '2026-01-09'
++tags:
++- testing/rules
++- testing
++- rule
++- cleanup
++updated_at: '2026-01-09T15:15:37Z'
++---
++
++## testing/rules (23:15:37)
++每次测试之前要清空我们的远程repo
+
+2026-01-09 23:22:39,822 - digest-worker - INFO - Checking line: '---'
+2026-01-09 23:22:39,822 - digest-worker - INFO - Checking line: 'created_at: '2026-01-09T15:15:37Z''
+2026-01-09 23:22:39,822 - digest-worker - INFO - Checking line: 'date: '2026-01-09''
+2026-01-09 23:22:39,822 - digest-worker - INFO - Checking line: 'tags:'
+2026-01-09 23:22:39,822 - digest-worker - INFO - Checking line: '- testing/rules'
+2026-01-09 23:22:39,822 - digest-worker - INFO - Checking line: '- testing'
+2026-01-09 23:22:39,822 - digest-worker - INFO - Checking line: '- rule'
+2026-01-09 23:22:39,822 - digest-worker - INFO - Checking line: '- cleanup'
+2026-01-09 23:22:39,822 - digest-worker - INFO - Checking line: 'updated_at: '2026-01-09T15:15:37Z''
+2026-01-09 23:22:39,822 - digest-worker - INFO - Checking line: '---'
+2026-01-09 23:22:39,822 - digest-worker - INFO - Checking line: ''
+2026-01-09 23:22:39,822 - digest-worker - INFO - Checking line: '## testing/rules (23:15:37)'
+2026-01-09 23:22:39,822 - digest-worker - INFO - MATCHED: testing/rules
+2026-01-09 23:22:39,822 - digest-worker - INFO - Checking line: '每次测试之前要清空我们的远程repo'
+2026-01-09 23:22:39,833 - digest-worker - INFO - Diff file: None
+2026-01-09 23:22:39,844 - digest-worker - INFO - Diff file: logs/2026-01-09.md
+2026-01-09 23:22:39,844 - digest-worker - INFO - RAW PATCH: @@ -0,0 +1,14 @@
++---
++created_at: '2026-01-09T23:22:35.089747'
++date: '2026-01-09'
++tags:
++- workflow
++- rule
++- project:gitmem
++- testing/rules
++- testing
++updated_at: '2026-01-09T23:22:35.089750'
++---
++
++## testing/rules (23:22:35)
++[Context: gitmem] 每次测试之前要清空我们的远程repo
+\ No newline at end of file
+
+2026-01-09 23:22:39,844 - digest-worker - INFO - Checking line: '---'
+2026-01-09 23:22:39,844 - digest-worker - INFO - Checking line: 'created_at: '2026-01-09T23:22:35.089747''
+2026-01-09 23:22:39,844 - digest-worker - INFO - Checking line: 'date: '2026-01-09''
+2026-01-09 23:22:39,844 - digest-worker - INFO - Checking line: 'tags:'
+2026-01-09 23:22:39,844 - digest-worker - INFO - Checking line: '- workflow'
+2026-01-09 23:22:39,844 - digest-worker - INFO - Checking line: '- rule'
+2026-01-09 23:22:39,844 - digest-worker - INFO - Checking line: '- project:gitmem'
+2026-01-09 23:22:39,844 - digest-worker - INFO - Checking line: '- testing/rules'
+2026-01-09 23:22:39,844 - digest-worker - INFO - Checking line: '- testing'
+2026-01-09 23:22:39,844 - digest-worker - INFO - Checking line: 'updated_at: '2026-01-09T23:22:35.089750''
+2026-01-09 23:22:39,844 - digest-worker - INFO - Checking line: '---'
+2026-01-09 23:22:39,844 - digest-worker - INFO - Checking line: ''
+2026-01-09 23:22:39,844 - digest-worker - INFO - Checking line: '## testing/rules (23:22:35)'
+2026-01-09 23:22:39,844 - digest-worker - INFO - MATCHED: testing/rules
+2026-01-09 23:22:39,844 - digest-worker - INFO - Checking line: '[Context: gitmem] 每次测试之前要清空我们的远程repo'
+2026-01-09 23:22:39,844 - digest-worker - INFO - Extracted 2 new entries.
+2026-01-09 23:22:50,919 - httpx - INFO - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
+2026-01-09 23:22:50,922 - digest-worker - INFO - Routed 'testing/rules' -> 'preferences'
+2026-01-09 23:23:03,496 - httpx - INFO - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
+2026-01-09 23:23:03,500 - digest-worker - INFO - Routed 'testing/rules' -> 'preferences'
+2026-01-09 23:23:03,500 - digest-worker - INFO - Merging updates into preferences.md...
+2026-01-09 23:23:16,582 - httpx - INFO - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
+2026-01-09 23:23:16,682 - digest-worker - INFO - Committed digest work. Ref: 305ea3ab130fce0713697fb20a0bdcf507191ad0
+2026-01-09 23:23:19,253 - digest-worker - INFO - Pushed changes to remote.
+2026-01-09 23:23:19,253 - gitmem-backend - INFO - Finished digest for: https://github.com/pipiandxixi/gitmem.git
diff --git a/src/digest/__pycache__/worker.cpython-313.pyc b/src/digest/__pycache__/worker.cpython-313.pyc
index 3558a4a..dce592f 100644
Binary files a/src/digest/__pycache__/worker.cpython-313.pyc and b/src/digest/__pycache__/worker.cpython-313.pyc differ
diff --git a/src/digest/worker.py b/src/digest/worker.py
index 8bb9b31..77a434d 100644
--- a/src/digest/worker.py
+++ b/src/digest/worker.py
@@ -90,6 +90,16 @@ class DiffParser:
         return entries
 
 class LLMClient:
+    CATEGORIES = {
+        "context": "事实背景: 客观存在的、静态的‘世界设定’。如项目简介、技术栈、环境配置、API地址。",
+        "preferences": "规则偏好: 用户主观设定的约束、喜好和交互习惯。如代码风格、回复语气、设计原则。",
+        "goals": "目标需求: 对未来的期望、愿景和具体需求。如产品愿景、功能Roadmap、用户故事清单。",
+        "progress": "状态经历: 动态的开发进度、过往决策和排查记录。如已完成功能、Debug历史、版本日志。",
+        "todos": "待办提示: 短期行动清单和需要注意的提醒。如TODO List、遗留Bug提醒、下次任务。",
+        "reference": "文档参考: 外部知识的沉淀、Cheatsheet和索引。如第三方库文档摘录、常用命令、外部链接。",
+        "misc": "其他碎片: 暂时无法归类的灵感或杂项。"
+    }
+
     def __init__(self):
         self.api_key = os.getenv("OPENAI_API_KEY")
         self.base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
@@ -101,24 +111,23 @@ class LLMClient:
         else:
             self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)
 
-    def route_topic(self, raw_topic: str, existing_index: Dict) -> str:
-        """Decide which canonical topic file should store this raw topic."""
-        if not self.client: return "general"
+    def route_topic(self, raw_topic: str) -> str:
+        """Decide which of the 7 pillars should store this raw topic."""
+        if not self.client: return "misc"
         
-        index_str = yaml.dump(existing_index)
+        cat_desc = "\n".join([f"- {k}: {v}" for k, v in self.CATEGORIES.items()])
         prompt = f"""
-        You are a librarian. Match the Raw Topic to an existing Canonical Topic from the Index. 
+        You are a Librarian. Categorize the following Raw Topic into one of the 7 Cognitive Pillars. 
         
-        Index:
-        {index_str}
+        Pillars:
+        {cat_desc}
         
         Raw Topic: "{raw_topic}"
         
         Rules:
-        1. Return ONLY the Canonical Topic name.
-        2. If it closely matches an existing topic, use it.
-        3. If it's a sub-topic, return the Parent Topic name.
-        4. If it's completely new, suggest a brief, snake_case filename (e.g. 'quant_server').
+        1. Return ONLY the Key name (e.g., 'context', 'preferences').
+        2. Do NOT create new categories.
+        3. If unsure, use 'misc'.
         """
         
         try:
@@ -127,31 +136,39 @@ class LLMClient:
                 messages=[{"role": "user", "content": prompt}],
                 temperature=0.0
             )
-            return response.choices[0].message.content.strip()
+            choice = response.choices[0].message.content.strip().lower()
+            # Clean up potential extra chars like 'context.' or 'Category: context'
+            if choice in self.CATEGORIES: return choice
+            for k in self.CATEGORIES:
+                if k in choice: return k
+            return "misc"
         except Exception as e:
             logger.error(f"LLM Routing failed: {e}")
-            return "general"
+            return "misc"
 
-    def digest_content(self, old_content: str, new_raw_data: str) -> str:
-        """Merge new raw data into old content."""
+    def digest_content(self, category: str, old_content: str, new_raw_data: str) -> str:
+        """Merge new raw data into the canonical pillar file."""
         if not self.client: return old_content + "\n\n" + new_raw_data
         
+        cat_info = self.CATEGORIES.get(category, "")
         prompt = f"""
-        You are the Knowledge Maintainer. Update the knowledge base file.
+        You are the Knowledge Maintainer for the pillar: "{category}" ({cat_info}).
+        Update this knowledge file with new information.
         
-        # Existing Knowledge:
-        {old_content[:10000]} ... (truncated if too long) 
+        # Existing Content:
+        {old_content[:15000]} ... (truncated if too long) 
         
         # New Raw Updates:
         {new_raw_data}
         
         # Task:
         1. Output the FULL updated Markdown content.
-        2. Merge new facts into appropriate sections.
-        3. Resolve conflicts (New Updates are truth).
-        4. If the new content is a file dump or code block, PRESERVE it exactly as is (do not summarize into bullets).
-        5. For general notes, use concise bullet points.
-        6. Keep the Front Matter (YAML) at the top.
+        2. MERGE new facts into existing sections (##) if they match.
+        3. If it's a new sub-topic, create a new ## header.
+        4. ELEGANTLY DEDUPLICATE: If the fact exists, update it if the new one is more recent/accurate.
+        5. PERSERVE code blocks and technical specs exactly.
+        6. Maintain a professional, manual-like tone.
+        7. Keep the Front Matter at the top.
         """
         
         try:
@@ -163,7 +180,7 @@ class LLMClient:
             return response.choices[0].message.content.strip()
         except Exception as e:
             logger.error(f"LLM Digestion failed: {e}")
-            return old_content # Fallback
+            return old_content
 
 class GitClient:
     def __init__(self, repo_path: str):
@@ -207,17 +224,10 @@ class DigestWorker:
         self.git = GitClient(repo_path)
         self.llm = LLMClient()
         self.knowledge_dir = os.path.join(repo_path, "knowledge")
-        self.index_path = os.path.join(self.knowledge_dir, "index.yaml")
         os.makedirs(self.knowledge_dir, exist_ok=True)
 
-    def load_index(self) -> Dict:
-        if os.path.exists(self.index_path):
-            with open(self.index_path, 'r') as f:
-                return yaml.safe_load(f) or {}
-        return {"topics": []}
-
     def run(self):
-        logger.info("Starting Digest Worker...")
+        logger.info("Starting Digest Worker (Cognitive Schema Mode)...")
         
         last_hash = self.git.get_last_processed_hash()
         current_head = self.git.repo.head.commit.hexsha
@@ -243,31 +253,30 @@ class DigestWorker:
              self.git.push()
              return
 
-        # 2. Group by Canonical Topic
-        index = self.load_index()
-        grouped_content = {} # {canonical_topic: [raw_content_list]}
+        # 2. Group by Pillar
+        grouped_content = {} # {pillar_key: [raw_content_list]}
         
         for entry in entries:
-            canonical = self.llm.route_topic(entry['topic'], index)
-            logger.info(f"Routed '{entry['topic']}' -> '{canonical}'")
-            if canonical not in grouped_content:
-                grouped_content[canonical] = []
-            grouped_content[canonical].append(entry['content'])
+            pillar = self.llm.route_topic(entry['topic'])
+            logger.info(f"Routed '{entry['topic']}' -> '{pillar}'")
+            if pillar not in grouped_content:
+                grouped_content[pillar] = []
+            grouped_content[pillar].append(entry['content'])
 
-        # 3. Digest & Write
-        for topic, contents in grouped_content.items():
-            topic_file = os.path.join(self.knowledge_dir, f"{topic}.md")
+        # 3. Digest & Merge into Pillar files
+        for pillar, contents in grouped_content.items():
+            topic_file = os.path.join(self.knowledge_dir, f"{pillar}.md")
             new_text = "\n\n".join(contents)
             
             old_text = ""
             if os.path.exists(topic_file):
                 with open(topic_file, 'r') as f: old_text = f.read()
             else:
-                old_text = f"---\ntitle: {topic}\ntags: []\n---\n# {topic}\n"
+                old_text = f"---\ntitle: {pillar.capitalize()}\ntags: []\n---\n# {pillar.capitalize()}\n"
             
-            # Call LLM to rewrite
-            logger.info(f"Digesting {topic}...")
-            final_text = self.llm.digest_content(old_text, new_text)
+            # Call LLM to rewrite and merge
+            logger.info(f"Merging updates into {pillar}.md...")
+            final_text = self.llm.digest_content(pillar, old_text, new_text)
             
             with open(topic_file, 'w') as f:
                 f.write(final_text)
@@ -326,4 +335,4 @@ if __name__ == "__main__":
              
     except Exception as e:
         logger.error(f"Worker failed: {e}")
-        sys.exit(1)
\ No newline at end of file
+        sys.exit(1)
diff --git a/src/server.py b/src/server.py
index 5e6d9e3..8b37b0d 100644
--- a/src/server.py
+++ b/src/server.py
@@ -75,6 +75,9 @@ def capture_context(scope: str = "all", git_url: str = None, git_token: str = No
     # Resolve config
     current_git_url = git_url or os.environ.get("GITMEM_URL")
     current_git_token = git_token or os.environ.get("GITMEM_TOKEN")
+    
+    # Identify Project Context
+    project_name = os.path.basename(os.getcwd())
 
     if not current_git_url:
         return "Error: GITMEM_URL is missing."
@@ -97,14 +100,18 @@ def capture_context(scope: str = "all", git_url: str = None, git_token: str = No
             if os.path.exists(full_path) and os.path.isfile(full_path):
                 try:
                     with open(full_path, 'r', encoding='utf-8') as f:
-                        content = f.read()
+                        raw_content = f.read()
+                    
+                    # Context Injection
+                    content = f"[Context: {project_name}] Source: {os.path.basename(full_path)}\n{raw_content}"
+                    
                     filename = os.path.basename(full_path)
                     topic = f"context/{s}/{filename}"
                     
                     res = store.remember(
                         content=content,
                         topic=topic,
-                        tags=["context", s, "auto-capture"],
+                        tags=["context", s, "auto-capture", f"project:{project_name}"],
                         git_url=current_git_url,
                         git_token=current_git_token
                     )
@@ -117,11 +124,11 @@ def capture_context(scope: str = "all", git_url: str = None, git_token: str = No
         try:
             diff_proc = subprocess.run(["git", "diff", "HEAD"], capture_output=True, text=True)
             if diff_proc.returncode == 0 and diff_proc.stdout.strip():
-                diff_content = diff_proc.stdout
+                diff_content = f"[Project: {project_name}] Git Diff Snapshot:\n{diff_proc.stdout}"
                 res = store.remember(
                     content=diff_content,
                     topic="context/project/git_diff",
-                    tags=["context", "project", "diff"],
+                    tags=["context", "project", "diff", f"project:{project_name}"],
                     git_url=current_git_url,
                     git_token=current_git_token
                 )
@@ -142,11 +149,22 @@ def remember(content: str, topic: str = "global", tags: List[str] = None,
     """
     current_git_url = git_url or os.environ.get("GITMEM_URL")
     current_git_token = git_token or os.environ.get("GITMEM_TOKEN")
+    
+    # Identify Project Context
+    project_name = os.path.basename(os.getcwd())
 
     if not current_git_url:
         return "Error: GITMEM_URL is missing."
+    
+    # Context Injection
+    enriched_content = f"[Context: {project_name}] {content}"
+    
+    # Tag Injection
+    tags = tags or []
+    if f"project:{project_name}" not in tags:
+        tags.append(f"project:{project_name}")
 
-    result = store.remember(content, topic, tags, dependencies, current_git_url, current_git_token)
+    result = store.remember(enriched_content, topic, tags, dependencies, current_git_url, current_git_token)
     
     if "Error:" not in result:
         _trigger_digest(current_git_url, current_git_token)
diff --git a/storage b/storage
index 782e1c0..93830e1 160000
--- a/storage
+++ b/storage
@@ -1 +1 @@
-Subproject commit 782e1c00cf4a90141cacc31c1d9684a8b924931d
+Subproject commit 93830e15b80a426174d88b29779c487e57f063b3